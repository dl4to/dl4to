{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cf2d0-5436-4de1-89e2-7078d856f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672afb0-23de-46ba-8821-86ca24d2924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import tarfile\n",
    "import torch\n",
    "from dl4to.datasets import TopoDataset, CSVConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e0a28-5ab9-464f-b586-a8a2de040dcd",
   "metadata": {},
   "source": [
    "# CSV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840bed0e-ad49-4249-8fd9-de15840d52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class CSVDataset(TopoDataset):\n",
    "    \"\"\"\n",
    "    A class for downloading, generating and importing datasets from CSV files. An inheriting class needs to override the method `_get_gz_file_paths_dict` for correct paths to the `.tar.gz` files that contain the `csv` files (see e.g. SELTO datasets).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root:str, # The root directory in which the datasets should be downloaded, generated and accessed.\n",
    "        name:str, # The name of the dataset that should be downloaded.\n",
    "        train:bool=True, # Whether the training or validation dataset should be generated.\n",
    "        size:int=-1, # The size of the dataset. If `size=-1`, then the whole dataset is imported. Useful if only subsets of the original dataset are needed.\n",
    "        download:bool=True, # Whether the dataset should be downloaded, if needed.\n",
    "        verbose:bool=True, # Whether to give the user feedback on the progress.\n",
    "        dtype:torch.dtype=torch.float32, # The datatype into which the values from the csv files are converted.\n",
    "        pde_solver:\"dl4to.pde.PDESolver\"=None, # The PDE solver that is used to solve the PDE for linear elasticity. Only has an effect if either `solve_pde_for_trivial_solution=True` or `solve_pde_for_gt_solution=True`.\n",
    "        solve_pde_for_trivial_solution:bool=False, # Whether to solve the PDE for each trivial solution and save the displacements in the solution object. These can later be accessed via `problem.trivial_solution.u`. This is useful if PDE preprocessing is used. Requires a PDE solver.\n",
    "        solve_pde_for_gt_solution:bool=False # Whether to solve the PDE for each ground truth and save the displacements in the solution object. These can later be accessed via `gt_solution.u`. Requires a PDE solver.\n",
    "    ):\n",
    "\n",
    "        dataset_name = self._get_dataset_name(name, train)\n",
    "        self._dtype = dtype\n",
    "        super().__init__(\n",
    "            name=dataset_name,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        self._size = size\n",
    "        self._pt_dir_path = self._get_pt_dir_path(train, root, name)\n",
    "        self._create_dirs(root, name)\n",
    "        self.pt_file_paths = self._get_pt_file_paths()\n",
    "\n",
    "        if len(self.pt_file_paths) == 0:\n",
    "            self._generate_dataset(\n",
    "                dataset_name=dataset_name, \n",
    "                download=download, \n",
    "                dtype=dtype, \n",
    "                verbose=verbose,\n",
    "                pde_solver=pde_solver,\n",
    "                solve_pde_for_trivial_solution=solve_pde_for_trivial_solution,\n",
    "                solve_pde_for_gt_solution=solve_pde_for_gt_solution\n",
    "            )\n",
    "            self.pt_file_paths = self._get_pt_file_paths()\n",
    "\n",
    "        self._load_dataset()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pt_dir_path(self):\n",
    "        return self._pt_dir_path\n",
    "\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self._dtype\n",
    "\n",
    "\n",
    "    def _generate_dataset(self, dataset_name, download, dtype, verbose, pde_solver, \n",
    "                          solve_pde_for_trivial_solution, solve_pde_for_gt_solution):\n",
    "        gz_file_paths = [f'{self.pt_dir_path}/{file_name}' for file_name in os.listdir(self.pt_dir_path) if file_name[-2:] == 'gz']\n",
    "\n",
    "        if len(gz_file_paths) == 0:\n",
    "            if download:\n",
    "                gz_file_path = self._download_gz_file(dataset_name)\n",
    "            else:\n",
    "                raise AttributeError('Dataset cannot be constructed with `download=False`.')\n",
    "        else:\n",
    "            if len(gz_file_paths) != 1:\n",
    "                raise AttributeError('Directory contains more than one `.gz` file.')\n",
    "            gz_file_path = gz_file_paths[0]\n",
    "\n",
    "        csv_dir_path = self._extract_gz_file(gz_file_path, dataset_name)\n",
    "\n",
    "        csv_converter = CSVConverter(\n",
    "            csv_dir_path=csv_dir_path,\n",
    "            dtype=dtype,\n",
    "            verbose=verbose,\n",
    "            pde_solver=pde_solver,\n",
    "            solve_pde_for_trivial_solution=solve_pde_for_trivial_solution,\n",
    "            solve_pde_for_gt_solution=solve_pde_for_gt_solution\n",
    "        )\n",
    "\n",
    "        csv_converter(self.pt_dir_path)\n",
    "        shutil.rmtree(csv_dir_path)\n",
    "\n",
    "\n",
    "    def _get_pt_file_paths(self):\n",
    "        file_names = os.listdir(self.pt_dir_path)\n",
    "        pt_file_paths = [f\"{self.pt_dir_path}/{name}\" for name in file_names if name[-2:] == 'pt']\n",
    "\n",
    "        if self.size == -1 or self.size == 0:\n",
    "            self._size = len(pt_file_paths)\n",
    "\n",
    "        pt_file_paths = pt_file_paths[:self.size]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Found {len(pt_file_paths)} files.\")\n",
    "\n",
    "        return pt_file_paths\n",
    "\n",
    "\n",
    "    def _load_dataset(self):\n",
    "        self.dataset = []\n",
    "\n",
    "        if self.verbose:\n",
    "            print('importing dataset...')\n",
    "            pt_file_paths = tqdm(self.pt_file_paths)\n",
    "\n",
    "        for pt_file_path in pt_file_paths:\n",
    "            self.dataset.append(torch.load(pt_file_path))\n",
    "\n",
    "        if self.verbose:\n",
    "            print('done!')\n",
    "\n",
    "\n",
    "    def _get_pt_dir_path(self, train, root, name):\n",
    "        if train:\n",
    "            return f'{root}/{name}/train'\n",
    "        return f'{root}/{name}/test'\n",
    "\n",
    "\n",
    "    def _get_dataset_name(self, name, train):\n",
    "        if train:\n",
    "            return f'{name}_train'\n",
    "        return f'{name}_test'\n",
    "\n",
    "\n",
    "    def _create_dirs(self, root, name):\n",
    "        if not os.path.exists(root):\n",
    "            os.makedirs(root)\n",
    "\n",
    "        if not os.path.exists(f'{root}/{name}'):\n",
    "            os.makedirs(f'{root}/{name}')\n",
    "\n",
    "        if not os.path.exists(self.pt_dir_path):\n",
    "            os.makedirs(self.pt_dir_path)\n",
    "\n",
    "\n",
    "    def _get_gz_file_paths_dict(self):\n",
    "        raise NotImplementedError(\"Must be overridden.\")\n",
    "\n",
    "\n",
    "    def _download_gz_file(self, dataset_name):\n",
    "        gz_file_path = f'{self.pt_dir_path}/{dataset_name}.tar.gz'\n",
    "        resources = self._get_gz_file_paths_dict()\n",
    "        url = resources[dataset_name]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Downloading {dataset_name}...\")\n",
    "\n",
    "        with open(gz_file_path, 'wb') as f:\n",
    "            r = requests.get(url)\n",
    "            f.write(r.content)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Done!\")\n",
    "        return gz_file_path\n",
    "\n",
    "\n",
    "    def _extract_gz_file(self, gz_file_path, dataset_name):\n",
    "        tar = tarfile.open(gz_file_path, 'r:gz')\n",
    "\n",
    "        csv_dir_path = f'{self.pt_dir_path}/csv'\n",
    "\n",
    "        if os.path.exists(csv_dir_path):\n",
    "            shutil.rmtree(csv_dir_path)\n",
    "\n",
    "        os.mkdir(csv_dir_path)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Extracting {dataset_name}...\")\n",
    "\n",
    "        tar.extractall(path=csv_dir_path)\n",
    "        tar.close()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Done!\")\n",
    "        return csv_dir_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
